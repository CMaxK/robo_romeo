{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95a0182e",
   "metadata": {},
   "source": [
    "# Main notebook for data processing in robo_romeo project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0614dc0a",
   "metadata": {},
   "source": [
    "## Imports - this should do us for the whole project. I have commented out the ones for model building later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8dbd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import string\n",
    "from pickle import dump\n",
    "from pickle import load\n",
    "import tensorflow as tf\n",
    "# from tensorflow.keras.applications.xception import Xception #to get pre-trained model Xception\n",
    "from tensorflow.keras.applications.xception import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer #for text tokenization\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "# from tensorflow.keras.layers.merge import add\n",
    "# from tensorflow.keras.models import Model, load_model\n",
    "# from tensorflow.keras.layers import Input, Dense#Keras to build our CNN and LSTM\n",
    "# from tensorflow.keras.layers import LSTM, Embedding, Dropout\n",
    "from tqdm import tqdm_notebook as tqdm #to check loop progress\n",
    "tqdm().pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32220b64",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c757e1",
   "metadata": {},
   "source": [
    " - load_fp( filename ) – To load the document file and read the contents of the file into a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a62943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the document file into memory\n",
    "def load_doc(filename):\n",
    "    # Open file to read\n",
    "    file = open(filename, 'r')\n",
    "    text = file.read()\n",
    "    file.close()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f124dab6",
   "metadata": {},
   "source": [
    " - img_capt( filename ) – To create a description dictionary that will map images with all 5 captions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d1071a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all images with their captions\n",
    "def img_capt(filename):\n",
    "    file = load_doc(filename)\n",
    "    captions = file.split('n')\n",
    "    descriptions ={}\n",
    "    for caption in captions[:-1]:\n",
    "        img, caption = caption.split('t')\n",
    "        if img[:-2] not in descriptions:\n",
    "            descriptions[img[:-2]] = [ caption ]\n",
    "        else:\n",
    "            descriptions[img[:-2]].append(caption)\n",
    "    return descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad247809",
   "metadata": {},
   "source": [
    " - txt_cleaning( descriptions) – to clean the data by taking all descriptions as input. This will perform several types of cleaning including uppercase to lowercase conversion, punctuation removal, and removal of the number containing words.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0372a892",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data cleaning function to convert all upper case alphabets to lowercase, removing punctuations and words containing numbers\n",
    "def txt_clean(captions):\n",
    "    table = str.maketrans('','',string.punctuation)\n",
    "    for img,caps in captions.items():\n",
    "        for i,img_caption in enumerate(caps):\n",
    "            img_caption.replace(\"-\",\" \")\n",
    "            descp = img_caption.split()\n",
    "          #uppercase to lowercase\n",
    "            descp = [wrd.lower() for wrd in descp]\n",
    "          #remove punctuation from each token\n",
    "            descp = [wrd.translate(table) for wrd in descp]\n",
    "          #remove hanging 's and a\n",
    "            descp = [wrd for wrd in descp if(len(wrd)>1)]\n",
    "          #remove words containing numbers with them\n",
    "            descp = [wrd for wrd in descp if(wrd.isalpha())]\n",
    "          #converting back to string\n",
    "            img_caption = ' '.join(desc)\n",
    "            captions[img][i]= img_caption\n",
    "    return captions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0b5488",
   "metadata": {},
   "source": [
    " - txt_vocab( descriptions ) – to create a vocabulary from all the unique words extracted out from descriptions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5b34bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def txt_vocab(descriptions):\n",
    "  # To build vocab of all unique words\n",
    "    vocab = set()\n",
    "    for key in descriptions.keys():\n",
    "        [vocab.update(d.split()) for d in descriptions[key]]\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2d8d34",
   "metadata": {},
   "source": [
    " - save_descriptions( descriptions, filename ) – This function is used to store all the preprocessed descriptions into a file.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236707c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e15d507",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To save all descriptions in one file\n",
    "def save_descriptions(descriptions, filename):\n",
    "    lines = list()\n",
    "    for key, desc_list in descriptions.items():\n",
    "        for desc in desc_list:\n",
    "            lines.append(key + 't' + desc )\n",
    "            data = \"n\".join(lines)\n",
    "            file = open(filename,\"w\")\n",
    "            file.write(data)\n",
    "            file.close()\n",
    "            # Saving to the path of the project folder\n",
    "            dataset_text = \"/Users/ChrisKarg/code/CMaxK/robo_romeo/raw_data/Flickr8k_text\"\n",
    "            dataset_images = \"/Users/ChrisKarg/code/CMaxK/robo_romeo/raw_data/Flicker8k_Dataset\"\n",
    "            #to prepare text data\n",
    "            filename = dataset_text + \"/\" + \"Flickr8k.token.txt\"\n",
    "            #loading the file that contains all data\n",
    "            #map them into descriptions dictionary \n",
    "            descriptions = img_capt(filename)\n",
    "            print(\"Length of descriptions =\" ,len(descriptions))\n",
    "            #cleaning the descriptions\n",
    "            clean_descriptions = txt_clean(descriptions)\n",
    "            #to build vocabulary\n",
    "            vocabulary = txt_vocab(clean_descriptions)\n",
    "            print(\"Length of vocabulary = \", len(vocabulary))\n",
    "            #saving all descriptions in one file\n",
    "            save_descriptions(clean_descriptions, \"descriptions.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973b084d",
   "metadata": {},
   "source": [
    "# loading dataset for model training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5296709",
   "metadata": {},
   "source": [
    "Flickr_8k.trainImages.txt contains a list of 6000 image names that are used for training\n",
    "\n",
    "Functions required to load the training datasets:\n",
    "\n",
    " - load_photos( fname ) – takes a file name as a parameter and return the list of image names by loading the text file into a string.\n",
    "\n",
    " - load_clean_descriptions( fname, image) – stores the captions for every image from the list of photos to a dictionary. For the ease of the LSTM model in identifying the beginning and ending of a caption, we append the and identifier with each caption. ('start' and 'end' tags at the beginning and end of each caption.\n",
    "\n",
    " - load_features(photos) – to return the extracted feature vectors from the Xception model and the dictionary for photos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c004e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data\n",
    "def load_photos(filename):\n",
    "    file = load_doc(filename)\n",
    "    photos = file.split(\"n\")[:-1]\n",
    "    return photos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214562d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_clean_descriptions(filename, photos):\n",
    "    #loading clean_descriptions\n",
    "    file = load_doc(filename)\n",
    "    descriptions = {}\n",
    "    for line in file.split(\"n\"):\n",
    "        words = line.split()\n",
    "        if len(words)<1 :\n",
    "            continue\n",
    "        image, image_caption = words[0], words[1:]\n",
    "        if image in photos:\n",
    "            if image not in descriptions:\n",
    "                descriptions[image] = []\n",
    "                desc = ' ' + \" \".join(image_caption) + ' '\n",
    "                descriptions[image].append(desc)\n",
    "    return descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276fdc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_features(photos):\n",
    "    #loading all features\n",
    "    all_features = load(open(\"features.p\",\"rb\"))\n",
    "    #selecting only needed features\n",
    "    features = {k:all_features[k] for k in photos}\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a497833a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = dataset_text + \"/\" + \"Flickr_8k.trainImages.txt\"\n",
    "#train = loading_data(filename)\n",
    "train_imgs = load_photos(filename)\n",
    "train_descriptions = load_clean_descriptions(\"descriptions.txt\", train_imgs)\n",
    "train_features = load_features(train_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad73146",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b4b799",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff24e697",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5184860",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c8569c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5752e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
