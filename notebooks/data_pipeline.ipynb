{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc024ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pickle\n",
    "import numpy as np\n",
    "from IPython import display\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB0\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.image import resize, resize_with_pad\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ddd8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneratorPipeline(tf.keras.utils.Sequence):\n",
    "\n",
    "    def __init__(self, X1, X2, y, batch_size,shuffle=False):\n",
    "        self.X1 = X1\n",
    "        self.X2 = X2\n",
    "        self.y = y\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.prepare_training_data()\n",
    "        self.make_dataset()\n",
    "\n",
    "# encode image using efficientnetb0\n",
    "# load encoded image\n",
    "\n",
    "    def cnn_instantiate(self):\n",
    "        \n",
    "        inputs = Input(shape=(500,400,3))\n",
    "        CNN_model = EfficientNetB0(\n",
    "        include_top=False, # Whether to include the fully-connected layer at the top of the network\n",
    "        weights='imagenet', # pre-trained weights on ImageNet\n",
    "        input_tensor=None,\n",
    "        input_shape= (500,400,3), # It should have 3 inputs channels\n",
    "        pooling=None # Optional pooling mode for feature extraction when include_top is False\n",
    "        )(inputs)\n",
    "        \n",
    "        pooling = GlobalAveragePooling2D()(CNN_model)\n",
    "        cnn_dense = Dense(256, activation='relu')(pooling)\n",
    "        model = Model(inputs=inputs, outputs=cnn_dense)\n",
    "        \n",
    "        img_list_file = '../raw_data/Flickr8k_text/Flickr_8k.trainImages.txt'\n",
    "        \n",
    "        img_folder_path = '../raw_data/Flickr8k_text'\n",
    "        \n",
    "    def extract_features_to_file(self, img_list_file, img_folder_path, features_file):\n",
    "    \n",
    "        features_dict = {}\n",
    "        img_list = np.loadtxt(img_list_file, dtype=str)\n",
    "\n",
    "        for image_name in img_list:\n",
    "            img_path = img_folder_path+image_name\n",
    "            img = image.load_img(img_path, target_size=(500,400,3))\n",
    "            x = image.img_to_array(img)\n",
    "            x = np.expand_dims(x, axis=0)\n",
    "            features = model.predict(x)\n",
    "\n",
    "            image_title = image_name.split('.')[0]\n",
    "            features_dict[image_title] = features\n",
    "\n",
    "        file = open(features_file,\"wb\")\n",
    "        pickle.dump(features_dict, file) \n",
    "        file.close()\n",
    "    \n",
    "    def prepare_training_data(self):\n",
    "    \n",
    "        features_file = '../output/extracted_features/extract_features_6k.pkl'\n",
    "        file = open(features_file, 'rb')\n",
    "        features_dict = pickle.load(file)\n",
    "        file.close()\n",
    "        \n",
    "        captions_file = '../output/extracted_features/cap4'\n",
    "        file = open(captions_file, 'rb')\n",
    "        x2_captions = pickle.load(file)\n",
    "        file.close()\n",
    "        \n",
    "        cap_img_list = x2_captions[0] # first column with list of repeated image id's\n",
    "        \n",
    "        X1 = []\n",
    "        \n",
    "        for cap_img in cap_img_list:\n",
    "            img_feature_matrix = features_dict[cap_img][0]\n",
    "            X1.append(img_feature_matrix)\n",
    "            \n",
    "        X1 = np.array(X1)[:100]\n",
    "        \n",
    "        X2 = np.array(x2_captions[1]).astype(np.uint32)[:100]\n",
    "        \n",
    "        y = np.array([el[0] if len(el)>0 else vocab_size+1 for el in x2_captions[2][:100]])\n",
    "        \n",
    "        data = pd.Dataframe({'X1': X1, 'X2': X2, 'y': y})\n",
    "        \n",
    "        return data\n",
    "                                                                    \n",
    "    def __getitem__(self,index):\n",
    "\n",
    "        self.load_image(X1)\n",
    "#         \"../raw_data/Flickr8k_text/.......\"\n",
    "        \n",
    "\n",
    "#         X1 = self.X1[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "#         X2 = self.X2[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "#         y = self.y[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "\n",
    "        return [X1,X2], y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            self.df = self.df.sample(frac=1).reset_index(drop=True)\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X1)//self.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c84e97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_instantiate():\n",
    "        \n",
    "        inputs = Input(shape=(500,400,3))\n",
    "        CNN_model = EfficientNetB0(\n",
    "        include_top=False, # Whether to include the fully-connected layer at the top of the network\n",
    "        weights='imagenet', # pre-trained weights on ImageNet\n",
    "        input_tensor=None,\n",
    "        input_shape= (500,400,3), # It should have exactly 3 inputs channels\n",
    "        pooling=None # Optional pooling mode for feature extraction when include_top is False\n",
    "        )(inputs)\n",
    "        \n",
    "        pooling = GlobalAveragePooling2D()(CNN_model)\n",
    "        cnn_dense = Dense(256, activation='relu')(pooling)\n",
    "        model = Model(inputs=inputs, outputs=cnn_dense)\n",
    "        \n",
    "        img_list_file = '../raw_data/Flickr8k_text/Flickr_8k.trainImages.txt'\n",
    "        \n",
    "        img_folder_path = '../raw_data/Flickr8k_text'\n",
    "        \n",
    "        print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1c915b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, 500, 400, 3)]     0         \n",
      "                                                                 \n",
      " efficientnetb0 (Functional)  (None, 16, 13, 1280)     4049571   \n",
      "                                                                 \n",
      " global_average_pooling2d_3   (None, 1280)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 256)               327936    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,377,507\n",
      "Trainable params: 4,335,484\n",
      "Non-trainable params: 42,023\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "encode_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6872bd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d32759",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475fa3e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c905b2ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7165aed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a192120",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d24958c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21852e20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2c2053c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_training_data(self):\n",
    "    \n",
    "        features_file = '../output/extracted_features/extract_features_6k.pkl'\n",
    "        file = open(features_file, 'rb')\n",
    "        features_dict = pickle.load(file)\n",
    "        file.close()\n",
    "        \n",
    "        captions_file = '../output/extracted_features/cap4'\n",
    "        file = open(captions_file, 'rb')\n",
    "        x2_captions = pickle.load(file)\n",
    "        file.close()\n",
    "        \n",
    "        cap_img_list = x2_captions[0] # first column with list of repeated image id's\n",
    "        \n",
    "        X1 = []\n",
    "        \n",
    "        for cap_img in cap_img_list:\n",
    "            img_feature_matrix = features_dict[cap_img][0]\n",
    "            X1.append(img_feature_matrix)\n",
    "            \n",
    "        X1 = np.array(X1)[:100]\n",
    "        \n",
    "        X2 = np.array(x2_captions[1]).astype(np.uint32)[:100]\n",
    "        \n",
    "        y = np.array([el[0] if len(el)>0 else vocab_size+1 for el in x2_captions[2][:100]])\n",
    "        \n",
    "        data = pd.Dataframe({'X1': X1, 'X2': X2, 'y': y})\n",
    "        \n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6b24ed22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ChrisKarg/code/CMaxK/robo_romeo/notebooks\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "86050504",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_file = '../raw_data/output/extracted_features/extract_features_6k.pkl'\n",
    "file = open(features_file, 'rb')\n",
    "features_dict = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d7a71ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "captions_file = '../raw_data/output/extracted_features/cap4'\n",
    "file = open(captions_file, 'rb')\n",
    "x2_captions = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3f81c792",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_img_list = x2_captions[0] # first column with list of repeated image id's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9a48c26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = []\n",
    "\n",
    "for cap_img in cap_img_list:\n",
    "    img_feature_matrix = features_dict[cap_img][0]\n",
    "    X1.append(img_feature_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce7ea67",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = np.array(X1)[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5951e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = np.array(x2_captions[1]).astype(np.uint32)[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fca7c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([el[0] if len(el)>0 else vocab_size+1 for el in x2_captions[2][:100]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bb8c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.Dataframe({'X1': X1, 'X2': X2, 'y': y})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
