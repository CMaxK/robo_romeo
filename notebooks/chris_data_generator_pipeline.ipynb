{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "088f6b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import Self\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04be57f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneratorPipeline(tf.keras.utils.Sequence):\n",
    "\n",
    "    def __init__(self, X1, X2, y, batch_size,shuffle=False):\n",
    "        self.X1 = X1\n",
    "        self.X2 = X2\n",
    "        self.y = y\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.prepare_training_data()\n",
    "\n",
    "# encode image using efficientnetb0\n",
    "# load encoded image\n",
    "\n",
    "    def prepare_training_data(self):\n",
    "    \n",
    "        features_file = '../output/extracted_features/extract_features_6k.pkl'\n",
    "        file = open(features_file, 'rb')\n",
    "        features_dict = pickle.load(file)\n",
    "        file.close()\n",
    "        \n",
    "        captions_file = '../output/extracted_features/cap'\n",
    "        file = open(captions_file, 'rb')\n",
    "        x2_captions = pickle.load(file)\n",
    "        file.close()\n",
    "        \n",
    "        cap_img_list = x2_captions[0] # first column with list of repeated image id's\n",
    "        \n",
    "        X1 = []\n",
    "        \n",
    "        for cap_img in cap_img_list:\n",
    "            img_feature_matrix = features_dict[cap_img][0]\n",
    "            X1.append(img_feature_matrix)\n",
    "            \n",
    "        X1 = np.array(X1)[:100]\n",
    "        \n",
    "        X2 = np.array(x2_captions[1]).astype(np.uint32)[:100]\n",
    "        \n",
    "        y = np.array([el[0] if len(el)>0 else vocab_size+1 for el in x2_captions[2][:100]])\n",
    "        \n",
    "        data = pd.DataFrame({'X1': X1, 'X2': X2, 'y': y})\n",
    "                                                                    \n",
    "    def __getitem__(self,index):\n",
    "\n",
    "        self.load_image(\"../raw_data/Flickr8k_text/.......\")\n",
    "        \n",
    "\n",
    "#         X1 = self.X1[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "#         X2 = self.X2[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "#         y = self.y[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "\n",
    "        return [X1,X2], y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            self.df = self.df.sample(frac=1).reset_index(drop=True)\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X1)//self.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5f3250",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "37a8174f27b66aa48088b371987b6f5829d12ab78f74d93e45c348145d421904"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
